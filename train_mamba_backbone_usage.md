# Mamba ä½œç‚º Backbone çš„ä½¿ç”¨æŒ‡å—

## ğŸ¯ å…©ç¨® Mamba ä½¿ç”¨æ–¹å¼å°æ¯”

### æ–¹æ¡ˆ Aï¼šMamba ä½œç‚º Backboneï¼ˆä½ æƒ³è¦çš„ï¼‰

```
åœ–ç‰‡ â†’ Mamba Backbone â†’ ç‰¹å¾µ â†’ åˆ†é¡
```

**å„ªé»**ï¼šMamba ç›´æ¥è™•ç†åœ–ç‰‡ï¼Œå®Œå…¨æ‹‹æ£„ CNN
**é©åˆ**ï¼šæƒ³æ¢ç´¢ Mamba åœ¨è¦–è¦ºä»»å‹™çš„æ½›åŠ›

### æ–¹æ¡ˆ Bï¼šCNN + Mamba èåˆï¼ˆæˆ‘ä¹‹å‰çµ¦çš„ï¼‰

```
åœ–ç‰‡ â†’ CNN Backbone â†’ ç‰¹å¾µ â†’ Mamba èåˆ â†’ åˆ†é¡
```

**å„ªé»**ï¼šçµåˆ CNN çš„è¦–è¦ºèƒ½åŠ›å’Œ Mamba çš„åºåˆ—å»ºæ¨¡
**é©åˆ**ï¼šè¿½æ±‚æœ€ä½³æ€§èƒ½

---

## ğŸš€ ä½¿ç”¨ Mamba Backbone è¨“ç·´

### æ­¥é©Ÿ 1: æ›´æ–° model_zoo.py

åœ¨ä½ çš„ `model_zoo.py` ä¸­æ·»åŠ ä¸Šé¢ä¸‰å€‹æ–°é¡åˆ¥ï¼š

- `VisionMambaBackbone` - Mamba è¦–è¦ºéª¨å¹¹
- `SignOrientedMambaBackboneNetwork` - äº”åˆ†æ”¯ Mamba
- `SimpleMambaBackbone` - ç°¡åŒ–ç‰ˆï¼ˆæ¸¬è©¦ç”¨ï¼‰

### æ­¥é©Ÿ 2: æ›´æ–° train.py çš„ get_model å‡½æ•¸

```python
def get_model(args):
    """æ ¹æ“š args å»ºç«‹å°æ‡‰çš„æ¨¡å‹"""
    from model_zoo import (
        SignOrientedNetwork,
        SimpleTimmModel,
        SignOrientedAttentionNetwork,
        SignOrientedMambaBackboneNetwork,  # æ–°å¢ï¼šMamba ä½œç‚º Backbone
        SignOrientedHybridNetwork,         # æ–°å¢ï¼šCNN + Mamba èåˆ
        SimpleMambaBackbone                # æ–°å¢ï¼šç°¡åŒ–ç‰ˆ
    )

    model_map = {
        'SignOriented': SignOrientedNetwork,
        'Simple': SimpleTimmModel,
        'SignOrientedAttention': SignOrientedAttentionNetwork,
        'MambaBackbone': SignOrientedMambaBackboneNetwork,  # ğŸ†•
        'MambaHybrid': SignOrientedHybridNetwork,           # ğŸ†•
        'SimpleMamba': SimpleMambaBackbone                  # ğŸ†•
    }

    if args.model not in model_map:
        raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹: {args.model}")

    model_class = model_map[args.model]

    # SimpleTimmModel
    if args.model == 'Simple':
        return model_class(
            num_classes=len(args.label_cols),
            backbone=args.backbone
        )

    # Mamba Backbone æ¨¡å‹
    elif args.model == 'MambaBackbone':
        return model_class(
            num_classes=len(args.label_cols),
            img_size=getattr(args, 'img_size', 224),
            patch_size=getattr(args, 'patch_size', 16),
            embed_dim=getattr(args, 'embed_dim', 512),
            depth=getattr(args, 'mamba_depth', 6),
            d_state=getattr(args, 'd_state', 16),
            feature_dim=args.feature_dim
        )

    # SimpleMamba
    elif args.model == 'SimpleMamba':
        return model_class(
            num_classes=len(args.label_cols),
            img_size=getattr(args, 'img_size', 224),
            patch_size=getattr(args, 'patch_size', 16),
            embed_dim=getattr(args, 'embed_dim', 384),
            depth=getattr(args, 'mamba_depth', 4),
            d_state=getattr(args, 'd_state', 16)
        )

    # Mamba Hybrid (CNN + Mamba)
    elif args.model == 'MambaHybrid':
        return model_class(
            num_classes=len(args.label_cols),
            backbone=args.backbone,
            feature_dim=args.feature_dim,
            d_state=getattr(args, 'd_state', 16)
        )

    # å…¶ä»–æ¨¡å‹
    else:
        return model_class(
            num_classes=len(args.label_cols),
            backbone=args.backbone,
            feature_dim=args.feature_dim
        )
```

### æ­¥é©Ÿ 3: æ·»åŠ å‘½ä»¤åˆ—åƒæ•¸

åœ¨ train.py çš„ argparse éƒ¨åˆ†æ·»åŠ ï¼š

```python
parser.add_argument('--model', type=str, required=True,
                    choices=['Simple', 'SignOriented', 'SignOrientedAttention',
                            'MambaBackbone', 'MambaHybrid', 'SimpleMamba'],
                    help='æ¨¡å‹æ¶æ§‹')

# Mamba Backbone å°ˆç”¨åƒæ•¸
parser.add_argument('--img_size', type=int, default=224,
                    help='è¼¸å…¥åœ–ç‰‡å¤§å°')
parser.add_argument('--patch_size', type=int, default=16,
                    help='Patch å¤§å°ï¼ˆMamba Backbone ç”¨ï¼‰')
parser.add_argument('--embed_dim', type=int, default=512,
                    help='Mamba embedding ç¶­åº¦')
parser.add_argument('--mamba_depth', type=int, default=6,
                    help='Mamba å±¤æ•¸')
parser.add_argument('--d_state', type=int, default=16,
                    help='Mamba ç‹€æ…‹ç©ºé–“ç¶­åº¦')
```

---

## ğŸ“ è¨“ç·´æŒ‡ä»¤ç¯„ä¾‹

### ğŸ”¥ é…ç½® 1: ç°¡å–®æ¸¬è©¦ï¼ˆæ¨è–¦é¦–æ¬¡ä½¿ç”¨ï¼‰

```bash
python train.py \
  --model SimpleMamba \
  --backbone dummy \
  --epochs 5 \
  --batch_size 16 \
  --lr 2e-4 \
  --embed_dim 256 \
  --mamba_depth 4 \
  --d_state 8 \
  --patch_size 16
```

### ğŸ”¥ é…ç½® 2: å®Œæ•´ Mamba Backboneï¼ˆäº”åˆ†æ”¯ï¼‰

```bash
python train.py \
  --model MambaBackbone \
  --backbone dummy \
  --epochs 30 \
  --batch_size 12 \
  --lr 1e-4 \
  --feature_dim 512 \
  --embed_dim 512 \
  --mamba_depth 6 \
  --d_state 16 \
  --patch_size 16 \
  --img_size 224
```

### ğŸ”¥ é…ç½® 3: CNN + Mamba æ··åˆï¼ˆæœ€å¼·æ€§èƒ½ï¼‰

```bash
python train.py \
  --model MambaHybrid \
  --backbone convnext_base \
  --epochs 30 \
  --batch_size 16 \
  --lr 1e-5 \
  --feature_dim 512 \
  --d_state 16
```

### ğŸ”¥ é…ç½® 4: å°å‹ Mambaï¼ˆé¡¯å­˜ä¸è¶³æ™‚ï¼‰

```bash
python train.py \
  --model MambaBackbone \
  --backbone dummy \
  --epochs 30 \
  --batch_size 24 \
  --lr 2e-4 \
  --feature_dim 384 \
  --embed_dim 384 \
  --mamba_depth 4 \
  --d_state 12 \
  --patch_size 16
```

---

## ğŸ›ï¸ è¶…åƒæ•¸èª¿æ•´æŒ‡å—

### Mamba Backbone å°ˆç”¨åƒæ•¸

| åƒæ•¸          | é è¨­å€¼ | ç¯„åœ    | å½±éŸ¿                              |
| ------------- | ------ | ------- | --------------------------------- |
| `embed_dim`   | 512    | 256-768 | Mamba ç‰¹å¾µç¶­åº¦ï¼Œè¶Šå¤§è¶Šå¼·ä½†è¶Šæ…¢    |
| `mamba_depth` | 6      | 4-12    | Mamba å±¤æ•¸ï¼Œé¡ä¼¼ Transformer æ·±åº¦ |
| `d_state`     | 16     | 8-32    | ç‹€æ…‹ç©ºé–“ç¶­åº¦ï¼Œæ§åˆ¶è¨˜æ†¶å®¹é‡        |
| `patch_size`  | 16     | 8/16/32 | Patch å¤§å°ï¼Œè¶Šå°åºåˆ—è¶Šé•·          |

### æ¨è–¦é…ç½®çµ„åˆ

#### è¼•é‡ç´šï¼ˆå¿«é€Ÿå¯¦é©—ï¼‰

```bash
--embed_dim 256 --mamba_depth 4 --d_state 8 --patch_size 16
```

#### æ¨™æº–ï¼ˆå¹³è¡¡æ€§èƒ½ï¼‰

```bash
--embed_dim 512 --mamba_depth 6 --d_state 16 --patch_size 16
```

#### é‡é‡ç´šï¼ˆè¿½æ±‚æ¥µè‡´ï¼‰

```bash
--embed_dim 768 --mamba_depth 12 --d_state 24 --patch_size 8
```

---

## ğŸ“Š ä¸‰ç¨®æ–¹æ¡ˆå°æ¯”

| æ–¹æ¡ˆ              | Backbone | èåˆæ–¹å¼   | åƒæ•¸é‡ | è¨“ç·´é€Ÿåº¦ | æ¨è–¦å ´æ™¯      |
| ----------------- | -------- | ---------- | ------ | -------- | ------------- |
| **SimpleMamba**   | Mamba    | å–®åˆ†æ”¯     | æœ€å°‘   | æœ€å¿«     | å¿«é€Ÿé©—è­‰      |
| **MambaBackbone** | Mamba    | æ‹¼æ¥       | ä¸­ç­‰   | ä¸­ç­‰     | ç´” Mamba æ–¹æ¡ˆ |
| **MambaHybrid**   | CNN      | Mamba èåˆ | æœ€å¤š   | è¼ƒæ…¢     | è¿½æ±‚æ€§èƒ½      |

---

## ğŸ”¬ å¯¦é©—å»ºè­°

### å°æ¯”å¯¦é©— 1: Backbone å°æ¯”

```bash
# A. å‚³çµ± CNN
python train.py --model SignOriented --backbone convnext_base

# B. Mamba Backbone
python train.py --model MambaBackbone --embed_dim 512 --mamba_depth 6

# C. CNN + Mamba æ··åˆ
python train.py --model MambaHybrid --backbone convnext_base --d_state 16
```

### å°æ¯”å¯¦é©— 2: Mamba æ·±åº¦å½±éŸ¿

```bash
# æ·ºå±¤ Mamba
python train.py --model MambaBackbone --mamba_depth 4

# ä¸­å±¤ Mamba
python train.py --model MambaBackbone --mamba_depth 6

# æ·±å±¤ Mamba
python train.py --model MambaBackbone --mamba_depth 12
```

### å°æ¯”å¯¦é©— 3: Patch å¤§å°å½±éŸ¿

```bash
# å¤§ Patch (åºåˆ—çŸ­ï¼Œé€Ÿåº¦å¿«)
python train.py --model MambaBackbone --patch_size 32

# ä¸­ Patch (å¹³è¡¡)
python train.py --model MambaBackbone --patch_size 16

# å° Patch (åºåˆ—é•·ï¼Œç´°ç¯€å¤š)
python train.py --model MambaBackbone --patch_size 8
```

---

## âš¡ æ•ˆèƒ½å„ªåŒ–

### å¦‚æœè¨“ç·´å¤ªæ…¢

1. **æ¸›å°‘ patch æ•¸é‡**

   ```bash
   --patch_size 32  # å¾ 16 æ”¹æˆ 32
   ```

2. **æ¸›å°‘ Mamba æ·±åº¦**

   ```bash
   --mamba_depth 4  # å¾ 6 æ”¹æˆ 4
   ```

3. **æ¸›å°‘ embedding ç¶­åº¦**
   ```bash
   --embed_dim 384  # å¾ 512 æ”¹æˆ 384
   ```

### å¦‚æœé¡¯å­˜ä¸è¶³

```bash
python train.py \
  --model SimpleMamba \
  --batch_size 8 \
  --embed_dim 256 \
  --mamba_depth 4 \
  --patch_size 16
```

---

## ğŸ› å¸¸è¦‹å•é¡Œ

### Q1: `--backbone dummy` æ˜¯ä»€éº¼æ„æ€ï¼Ÿ

A: ç•¶ä½¿ç”¨ `MambaBackbone` æˆ– `SimpleMamba` æ™‚ï¼Œä¸éœ€è¦ CNN backboneï¼Œä½† argparse å¯èƒ½è¦æ±‚é€™å€‹åƒæ•¸ï¼Œæ‰€ä»¥å¡« `dummy` ä½œç‚ºä½”ä½ç¬¦ã€‚

### Q2: Mamba Backbone æ¯” CNN æ…¢å—ï¼Ÿ

A: å–æ±ºæ–¼é…ç½®ï¼š

- å°å‹ Mamba (`depth=4, embed_dim=256`) æ¯” CNN å¿«
- å¤§å‹ Mamba (`depth=12, embed_dim=768`) æ¯” CNN æ…¢

### Q3: è©²é¸å“ªå€‹æ¨¡å‹ï¼Ÿ

A:

- **æƒ³å¿«é€Ÿé©—è­‰**: `SimpleMamba`
- **æƒ³ç´” Mamba**: `MambaBackbone`
- **æƒ³è¦æœ€ä½³æ€§èƒ½**: `MambaHybrid` (CNN + Mamba)

---

## ğŸ“ Mamba ä½œç‚º Backbone çš„åŸç†

### ç‚ºä»€éº¼ Mamba å¯ä»¥ç•¶ Backboneï¼Ÿ

1. **Patch åºåˆ—åŒ–**: åœ–ç‰‡åˆ‡æˆ 16x16 patches â†’ è®Šæˆåºåˆ—
2. **ä½ç½®ç·¨ç¢¼**: åŠ ä¸Šä½ç½®è³‡è¨Š
3. **Mamba è™•ç†**: ç”¨ç‹€æ…‹ç©ºé–“æ¨¡å‹è™•ç†é€™å€‹åºåˆ—
4. **å…¨å±€æ± åŒ–**: å¹³å‡æ‰€æœ‰ patch ç‰¹å¾µ

```
è¼¸å…¥åœ–ç‰‡ (224x224x3)
    â†“
åˆ‡æˆ Patches (196å€‹ 16x16 patches)
    â†“
Patch Embedding (196x512)
    â†“
+ ä½ç½®ç·¨ç¢¼
    â†“
Mamba Block 1
Mamba Block 2
...
Mamba Block N
    â†“
Global Pooling â†’ (512ç¶­å‘é‡)
    â†“
åˆ†é¡å™¨ â†’ 8é¡æ¨™ç±¤
```

é€™å°±åƒ Vision Transformer (ViT)ï¼Œä½†æŠŠ Attention æ›æˆ Mambaï¼

---

## âœ… å¿«é€Ÿé–‹å§‹

```bash
# 1. ç¢ºä¿ç’°å¢ƒæ­£ç¢º
conda activate mamba_stable
cd /mnt/c/Users/peter/Tongue-AI-V2

# 2. å¿«é€Ÿæ¸¬è©¦ï¼ˆ3-5åˆ†é˜ï¼‰
python train.py \
  --model SimpleMamba \
  --backbone dummy \
  --epochs 3 \
  --batch_size 16 \
  --lr 2e-4

# 3. å¦‚æœæˆåŠŸï¼Œé€²è¡Œå®Œæ•´è¨“ç·´
python train.py \
  --model MambaBackbone \
  --backbone dummy \
  --epochs 30 \
  --batch_size 12 \
  --lr 1e-4 \
  --embed_dim 512 \
  --mamba_depth 6
```

ç¾åœ¨ä½ çœŸçš„å¯ä»¥æŠŠ Mamba ç•¶ä½œ Backbone ä½¿ç”¨äº†ï¼ğŸš€
