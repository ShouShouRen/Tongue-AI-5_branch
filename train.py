# train.py - K-Fold äº¤å‰é©—è­‰æ¨™æº–æµç¨‹
# --- ç§»é™¤äº† Phase 2 (Final Training)ï¼Œåªä¿ç•™ K-Fold æœ€ä½³æ¨¡å‹ ---

import os
import gc
import json
import warnings
import torch
from torch.utils.data import DataLoader
from torch import optim
from tqdm import tqdm
import numpy as np
import pandas as pd
import argparse

# å¾æ¨¡å‹åº«åŒ¯å…¥æ‰€æœ‰æ¨¡å‹
from model import (
    SignOrientedNetwork, 
    SimpleTimmModel, 
    SignOrientedAttentionNetwork,
    SignOrientedMambaVisionNetwork,
    SimpleMambaVision,
    MambaVisionWithMambaFusion
)
from dataset import TongueDataset
from samplers import build_multilabel_weighted_sampler
from torch.cuda.amp import autocast, GradScaler
from sklearn.metrics import f1_score, accuracy_score

# å˜—è©¦è¼‰å…¥è‡ªå®šç¾©æå¤±å‡½æ•¸
try:
    from losses import ClassBalancedBCELoss
except ImportError:
    print("âš ï¸ ClassBalancedBCELoss not found, using standard BCEWithLogitsLoss")
    ClassBalancedBCELoss = None

warnings.filterwarnings('ignore')
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'


def get_model(args):
    """æ ¹æ“š args å»ºç«‹å°æ‡‰çš„æ¨¡å‹"""
    
    # SimpleTimmModel - å–®åˆ†æ”¯ CNN
    if args.model == 'Simple':
        return SimpleTimmModel(
            num_classes=len(args.label_cols),
            backbone=args.backbone,
            img_size=args.img_size  # ç¢ºä¿ img_size è¢«å‚³é
        )
    
    # SignOriented - åŸå§‹äº”åˆ†æ”¯æ¨¡å‹
    elif args.model == 'SignOriented':
        return SignOrientedNetwork(
            num_classes=len(args.label_cols),
            backbone=args.backbone,
            feature_dim=args.feature_dim
        )
    
    # SignOrientedAttention - Transformer Attention èåˆ
    elif args.model == 'SignOrientedAttention':
        return SignOrientedAttentionNetwork(
            num_classes=len(args.label_cols),
            backbone=args.backbone,
            feature_dim=args.feature_dim
        )
    elif args.model == 'MambaVision':
        return SignOrientedMambaVisionNetwork(
            num_classes=len(args.label_cols),
            mamba_vision_model=args.mamba_vision_model,
            feature_dim=args.feature_dim,
            pretrained=args.pretrained,
            freeze_backbone=args.freeze_backbone
        )
    
    elif args.model == 'SimpleMambaVision':
        return SimpleMambaVision(
            num_classes=len(args.label_cols),
            mamba_vision_model=args.mamba_vision_model,
            pretrained=args.pretrained,
            freeze_backbone=args.freeze_backbone
        )
    
    elif args.model == 'MambaVisionFusion':
        return MambaVisionWithMambaFusion(
            num_classes=len(args.label_cols),
            mamba_vision_model=args.mamba_vision_model,
            feature_dim=args.feature_dim,
            d_state=args.d_state,
            pretrained=args.pretrained,
            freeze_backbone=args.freeze_backbone
        )
    
    else:
        raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹æ¶æ§‹: {args.model}")


def clear_gpu_memory():
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    gc.collect()


@torch.no_grad()
def evaluate_model_and_find_thresholds(model, data_loader, device, label_cols, threshold_grid=None):
    if threshold_grid is None:
        threshold_grid = np.arange(0.1, 0.95, 0.05)

    model.eval()
    all_probs, all_labels = [], []
    loop = tqdm(data_loader, desc="Validating", leave=False)
    for (x_whole, x_root, x_center, x_side, x_tip), labels in loop:
        logits = model(
            x_whole.to(device), 
            x_root.to(device), 
            x_center.to(device), 
            x_side.to(device), 
            x_tip.to(device)
        )
        probs = torch.sigmoid(logits).float().cpu().numpy()
        all_probs.append(probs)
        all_labels.append(labels.cpu().numpy())

    if not all_probs:
        return None, None

    P = np.vstack(all_probs)
    Y = np.vstack(all_labels)
    C = Y.shape[1]

    best_thresholds = np.zeros(C, dtype=np.float32)
    best_f1_per_class = np.zeros(C, dtype=np.float32)

    for i in range(C):
        if Y[:, i].sum() == 0:
            best_thresholds[i], best_f1_per_class[i] = 0.5, 0.0
            continue
        best_f1, best_th = -1.0, 0.5
        for th in threshold_grid:
            pred = (P[:, i] > th).astype(int)
            f1 = f1_score(Y[:, i], pred, zero_division=0)
            if f1 > best_f1:
                best_f1, best_th = f1, th
        best_thresholds[i], best_f1_per_class[i] = best_th, best_f1

    preds_best = np.array([P[:, i] > best_thresholds[i] for i in range(C)]).T
    
    metrics_at_best = {
        'f1_macro': np.mean(best_f1_per_class).item(),
        'subset_acc': accuracy_score(Y, preds_best)
    }
    return metrics_at_best, best_thresholds


def train_model(args, train_csv, val_csv, model_path):
    clear_gpu_memory()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    train_set = TongueDataset(train_csv, args.image_root, args.label_cols, is_train=True)
    sampler, n_pos_t, n_neg_t = build_multilabel_weighted_sampler(train_csv, args.label_cols)
    train_loader = DataLoader(
        train_set, 
        batch_size=args.batch_size, 
        sampler=sampler, 
        num_workers=args.num_workers, 
        pin_memory=True, 
        drop_last=True
    )
    
    val_loader = None
    if val_csv:
        val_set = TongueDataset(val_csv, args.image_root, args.label_cols, is_train=False)
        val_loader = DataLoader(
            val_set, 
            batch_size=args.batch_size * 2, 
            shuffle=False, 
            num_workers=args.num_workers, 
            pin_memory=True
        )

    model = get_model(args).to(device)
    
    # è¨ˆç®—æ¨¡å‹åƒæ•¸é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"ğŸ“Š Model Parameters: {total_params:,} total, {trainable_params:,} trainable")
    
    # æå¤±å‡½æ•¸
    if ClassBalancedBCELoss is not None:
        criterion = ClassBalancedBCELoss(
            n_pos=n_pos_t.to(device), 
            n_neg=n_neg_t.to(device), 
            beta=0.9999
        )
    else:
        criterion = torch.nn.BCEWithLogitsLoss()
        
    optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
            optimizer, 
            T_0=10,      # æ¯ 10 å€‹ epoch é‡å•Ÿä¸€æ¬¡
            T_mult=2,    # æ¯æ¬¡é‡å•Ÿå¾Œï¼Œé€±æœŸåŠ å€ï¼ˆ10 â†’ 20 â†’ 40ï¼‰
            eta_min=1e-7 # æœ€å°å­¸ç¿’ç‡
        )
    scaler = GradScaler()
    
    best_f1_macro, patience_counter = -1.0, 0

    for epoch in range(args.epochs):
        model.train()
        total_loss, n_batches = 0.0, 0
        loop = tqdm(train_loader, desc=f"Epoch {epoch+1}/{args.epochs} Training", leave=False)
        
        for (x_whole, x_root, x_center, x_side, x_tip), labels in loop:
            with autocast():
                logits = model(
                    x_whole.to(device), 
                    x_root.to(device), 
                    x_center.to(device), 
                    x_side.to(device), 
                    x_tip.to(device)
                )
                loss = criterion(logits, labels.to(device))
            
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            optimizer.zero_grad()
            
            total_loss += loss.item()
            n_batches += 1
            loop.set_postfix(loss=total_loss / n_batches)
        
        scheduler.step()

        if val_loader:
            metrics, best_thresholds = evaluate_model_and_find_thresholds(
                model, val_loader, device, args.label_cols
            )
            if metrics:
                print(f"\nEpoch {epoch+1}/{args.epochs} | Train Loss: {total_loss/n_batches:.4f} | "
                      f"Val F1-Macro: {metrics['f1_macro']:.4f} | Val Subset-Acc: {metrics['subset_acc']:.4f}")
                
                if metrics['f1_macro'] > best_f1_macro:
                    best_f1_macro = metrics['f1_macro']
                    state = {'model_state_dict': model.state_dict()}
                    torch.save(state, model_path)
                    
                    th_path = os.path.splitext(model_path)[0] + "_best_thresholds.json"
                    with open(th_path, "w", encoding="utf-8") as f:
                        json.dump(
                            {label: float(th) for label, th in zip(args.label_cols, best_thresholds)}, 
                            f, indent=2
                        )
                    print(f"âœ… Saved best model to {os.path.basename(model_path)}")
                    patience_counter = 0
                else:
                    patience_counter += 1
                    if patience_counter >= args.patience:
                        print(f"Early stopping at epoch {epoch+1}")
                        break
        else:
            # é€™ç¨®æƒ…æ³ç¾åœ¨åªæœƒåœ¨ val_csv=None æ™‚ç™¼ç”Ÿï¼Œ
            # ä¹Ÿå°±æ˜¯åœ¨è¢«æˆ‘å€‘ç§»é™¤çš„ Phase 2 ä¸­ã€‚
            # ç‚ºäº†ä¿éšªèµ·è¦‹ï¼Œæˆ‘å€‘ä»ç„¶ä¿ç•™é€™æ®µç¨‹å¼ç¢¼ï¼Œ
            # å„˜ç®¡åœ¨ K-Fold æµç¨‹ä¸­å®ƒä¸æ‡‰è©²è¢«åŸ·è¡Œã€‚
            print(f"\nEpoch {epoch+1}/{args.epochs} | Train Loss: {total_loss/n_batches:.4f}")

    # ç§»é™¤äº† if not val_loader: ... çš„å€å¡Šï¼Œ
    # å› ç‚ºæˆ‘å€‘åªé—œå¿ƒåœ¨æœ‰ val_loader æ™‚å„²å­˜çš„æœ€ä½³æ¨¡å‹ã€‚
    
    return best_f1_macro


def combine_kfold_csvs(k, output_path):
    # é€™å€‹å‡½å¼ç¾åœ¨ä¸æœƒè¢«å‘¼å«ï¼Œä½†å¯ä»¥ä¿ç•™
    all_dfs = []
    for i in range(1, k + 1):
        for f in [f'train_fold{i}.csv', f'val_fold{i}.csv']:
            if os.path.exists(f):
                all_dfs.append(pd.read_csv(f))
    
    if not all_dfs:
        return None
    
    combined = pd.concat(all_dfs).drop_duplicates().reset_index(drop=True)
    combined.to_csv(output_path, index=False)
    print(f"âœ” Combined CSV saved to {output_path} with {len(combined)} rows.")
    return output_path


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='è¨“ç·´èˆŒè±¡è¾¨è­˜æ¨¡å‹ï¼ˆæ”¯æ´ Mambaï¼‰')
    
    # æ¨¡å‹é¸æ“‡
    parser.add_argument('--model', type=str, required=True,
                        choices=[
                            'Simple',
                            'SignOriented',
                            'SignOrientedAttention',
                            'MambaVision',
                            'SimpleMambaVision',
                            'MambaVisionFusion'
                        ],
                        help='æ¨¡å‹æ¶æ§‹')
    
    parser.add_argument('--backbone', type=str, default='convnext_base',
                        help='CNN éª¨å¹¹ç¶²è·¯ï¼ˆCNN æ¨¡å‹ç”¨ï¼‰')
    
    # è¨“ç·´åƒæ•¸
    parser.add_argument('--epochs', type=int, default=30, help='è¨“ç·´ Epoch æ•¸')
    parser.add_argument('--batch_size', type=int, default=16, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--lr', type=float, default=1e-5, help='å­¸ç¿’ç‡')
    parser.add_argument('--patience', type=int, default=7, help='Early stopping è€å¿ƒå€¼')
    
    # æ¨¡å‹æ¶æ§‹åƒæ•¸ï¼ˆé€šç”¨ï¼‰
    parser.add_argument('--feature_dim', type=int, default=512, 
                        help='ç‰¹å¾µç¶­åº¦')
    
    # Mamba å°ˆç”¨åƒæ•¸
    parser.add_argument('--d_state', type=int, default=16, 
                        help='Mamba ç‹€æ…‹ç©ºé–“ç¶­åº¦')
    parser.add_argument('--num_mamba_layers', type=int, default=2, 
                        help='Mamba å±¤æ•¸ï¼ˆDeepMamba ç”¨ï¼‰')
    
    # Mamba Backbone å°ˆç”¨åƒæ•¸
    parser.add_argument('--img_size', type=int, default=224, 
                        help='è¼¸å…¥åœ–ç‰‡å¤§å°')
    parser.add_argument('--patch_size', type=int, default=16, 
                        help='Patch å¤§å°ï¼ˆMamba Backbone ç”¨ï¼‰')
    parser.add_argument('--embed_dim', type=int, default=512, 
                        help='Mamba embedding ç¶­åº¦')
    parser.add_argument('--mamba_depth', type=int, default=6, 
                        help='Mamba Backbone æ·±åº¦')
                        
    # <-- ğŸ”¥ 3b. åœ¨é€™è£¡åŠ å…¥æ–°çš„æ¬Šé‡è·¯å¾‘åƒæ•¸ -->

    
    # è³‡æ–™è·¯å¾‘
    parser.add_argument('--image_root', type=str, default='images', 
                        help='åœ–ç‰‡æ ¹ç›®éŒ„')
    parser.add_argument('--num_workers', type=int, default=4, 
                        help='è³‡æ–™è¼‰å…¥ç·šç¨‹æ•¸')
    parser.add_argument('--mamba_vision_model', type=str, 
                        default='mamba_vision_T',
                        choices=['mamba_vision_T', 'mamba_vision_T2', 
                                 'mamba_vision_S', 'mamba_vision_B', 'mamba_vision_L'],
                        help='(MambaVision ç”¨) MambaVision æ¨¡å‹å¤§å°')
    
    parser.add_argument('--pretrained', action='store_true', default=True,
                        help='(MambaVision ç”¨) æ˜¯å¦ä½¿ç”¨é è¨“ç·´æ¬Šé‡')
    
    parser.add_argument('--freeze_backbone', action='store_true', default=False,
                        help='(MambaVision ç”¨) æ˜¯å¦å‡çµ backboneï¼Œåªè¨“ç·´åˆ†é¡é ­')
    
    args = parser.parse_args()

    # æ¨™ç±¤æ¬„ä½
    args.label_cols = ['TonguePale', 'TipSideRed', 'Spot', 'Ecchymosis',
                       'Crack', 'Toothmark', 'FurThick', 'FurYellow']
    NUM_FOLDS = 5

    # --- ğŸ”¥ é—œéµä¿®æ”¹ï¼šå»ºç«‹å”¯ä¸€çš„å¯¦é©—åç¨± ---
    if args.model in ['Simple', 'SignOriented', 'SignOrientedAttention']:
        experiment_name = f'{args.model}_{args.backbone}'
    elif args.model in ['MambaVision', 'SimpleMambaVision', 'MambaVisionFusion']:
        experiment_name = f'{args.model}_{args.mamba_vision_model}'
    else:
        experiment_name = f'{args.model}_{args.backbone}'
    
    print(f"ğŸ“¦ å¯¦é©—åç¨± (å°‡ç”¨æ–¼å­˜æª”): {experiment_name}")
    # --- çµæŸä¿®æ”¹ ---


    # é¡¯ç¤ºé…ç½®
    print("="*70)
    print("   è¨“ç·´é…ç½®")
    print("="*70)
    print(f"   æ¨¡å‹: {args.model}")
    
    if args.model in ['MambaBackbone', 'SimpleMamba']:
        print(f"   Mamba è¨­ç½®:")
        print(f"     - Embedding ç¶­åº¦: {args.embed_dim}")
        print(f"     - Mamba æ·±åº¦: {args.mamba_depth}")
        print(f"     - ç‹€æ…‹ç¶­åº¦: {args.d_state}")
        print(f"     - Patch å¤§å°: {args.patch_size}")
    else:
        print(f"   éª¨å¹¹: {args.backbone}")
        print(f"   ç‰¹å¾µç¶­åº¦: {args.feature_dim}")
        if 'Mamba' in args.model:
            print(f"   Mamba ç‹€æ…‹ç¶­åº¦: {args.d_state}")
            if args.model == 'SignOrientedDeepMamba':
                print(f"   Mamba å±¤æ•¸: {args.num_mamba_layers}")
    
    print(f"   Epochs: {args.epochs}")
    print(f"   Batch Size: {args.batch_size}")
    print(f"   Learning Rate: {args.lr}")
    print("="*70)

    # Phase 1: K-Fold Cross-Validation
    print("\n" + "="*30 + "\n   PHASE 1: K-Fold CV\n" + "="*30)
    for i in range(1, NUM_FOLDS + 1):
        train_csv = f'train_fold{i}.csv'
        val_csv = f'val_fold{i}.csv'
        
        if not all(os.path.exists(f) for f in [train_csv, val_csv]):
            print(f"âš ï¸   Skipping Fold {i}: CSV files not found")
            continue
        
        model_path = f'{experiment_name}_fold{i}.pth'
        
        print(f"\n{'='*60}")
        print(f"   Training Fold {i}/{NUM_FOLDS}")
        print(f"{'='*60}")
        train_model(args, train_csv, val_csv, model_path)

    # --- ğŸ”¥ é—œéµä¿®æ”¹ï¼šç§»é™¤äº† Phase 2 (Final Training) ---
    # print("\n" + "="*30 + "\n   PHASE 2: Final Training\n" + "="*30)
    # full_train_csv = combine_kfold_csvs(NUM_FOLDS, 'train_full.csv')
    # final_model_path = f'{experiment_name}_final.pth'
    # 
    # if full_train_csv:
    #     print(f"\n{'='*60}")
    #     print(f"   Training Final Model")
    #     print(f"{'='*60}")
    #     train_model(args, full_train_csv, None, final_model_path)
    # --- çµæŸä¿®æ”¹ ---


    # Phase 3: Average Thresholds
    print("\n" + "="*30 + "\n   PHASE 3: Average Thresholds\n" + "="*30)
    all_thresholds = []
    
    for i in range(1, NUM_FOLDS + 1):
        th_path = f'{experiment_name}_fold{i}_best_thresholds.json'
        
        if os.path.exists(th_path):
            with open(th_path, 'r', encoding='utf-8') as f:
                fold_ths = json.load(f)
                all_thresholds.append([fold_ths.get(label, 0.5) for label in args.label_cols])
                print(f"âœ“ Loaded {os.path.basename(th_path)}")
    
    if all_thresholds:
        avg_thresholds = {
            label: float(th) 
            for label, th in zip(args.label_cols, np.mean(all_thresholds, axis=0))
        }
        
        # é€™å€‹ "final" æª”æ¡ˆç¾åœ¨ä»£è¡¨çš„æ˜¯ K-Fold çš„å¹³å‡å€¼
        final_th_path = f'{experiment_name}_final_best_thresholds.json'
        
        with open(final_th_path, 'w', encoding='utf-8') as f:
            json.dump(avg_thresholds, f, indent=2)
        
        print(f"\nâœ… Averaged thresholds saved to: {final_th_path}")
        for label, th in avg_thresholds.items():
            print(f"   - {label:<15}: {th:.4f}")
    
    print("\n" + "="*70)
    print("   âœ… K-Fold è¨“ç·´å®Œæˆï¼")
    print("="*70)
