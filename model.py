# model.py â€” æ¨¡åž‹åº«ï¼šå­˜æ”¾å¤šå€‹å¯é¸çš„æ¨¡åž‹æž¶æ§‹
# --- æ–°å¢ž Mamba æ¨¡åž‹ ---
import sys
import os
# å°‡ç›®å‰æª”æ¡ˆ (model.py) æ‰€åœ¨çš„ç›®éŒ„ (å°ˆæ¡ˆæ ¹ç›®éŒ„) åŠ å…¥åˆ° Python çš„æœå°‹è·¯å¾‘
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
import torch
import torch.nn as nn
from timm import create_model
from mamba_ssm import Mamba

# --- æ–¹æ¡ˆäºŒ(å›°é›£ç‰ˆ) æ‰€éœ€çš„é¡å¤–åŒ¯å…¥ ---
import os
from collections import OrderedDict

# -----------------------------------------------------------------------------
# æ¨¡åž‹ä¸€ï¼šæ‚¨åŽŸæœ¬çš„äº”åˆ†æ”¯æ¨¡åž‹ (SignOrientedNetwork)
# -----------------------------------------------------------------------------
class SignOrientedNetwork(nn.Module):
    def __init__(self, num_classes=8, backbone='swin_base_patch4_window7_224', feature_dim=512):
        super().__init__()
        print(f"Initializing SignOrientedNetwork with backbone: {backbone}")

        self.encoder = create_model(backbone, pretrained=True, features_only=True)
        self.enc_dim = self.encoder.feature_info.channels()[-1]

        self.branch_hints = {
            "side":   [1,1,1,1,0,1,0,0], "tip":    [1,1,0,1,0,0,0,0],
            "center": [0,0,0,0,1,0,1,1], "root":   [0,1,0,0,1,0,0,0],
            "whole":  [1,1,1,1,1,1,1,1],
        }

        self.branch_proj = nn.ModuleDict({
            name: nn.Sequential(
                nn.Linear(self.enc_dim + num_classes, feature_dim),
                nn.ReLU(inplace=True),
                nn.Dropout(0.1)
            ) for name in self.branch_hints.keys()
        })

        self.pool = nn.AdaptiveAvgPool2d(1)
        self.flatten = nn.Flatten()
        fused_dim = feature_dim * 5
        self.classifier = nn.Sequential(
            nn.Linear(fused_dim, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )

    def _encode(self, x: torch.Tensor) -> torch.Tensor:
        feat = self.encoder(x)[-1]
        if feat.dim() == 4 and feat.shape[-1] == self.enc_dim:
            feat = feat.permute(0, 3, 1, 2).contiguous()
        return self.flatten(self.pool(feat)) if feat.dim() == 4 else feat

    def _add_hint(self, flat: torch.Tensor, branch_name: str, device) -> torch.Tensor:
        hint = torch.tensor(self.branch_hints[branch_name], device=device, dtype=torch.float32)
        hint = hint.unsqueeze(0).expand(flat.size(0), -1)
        return self.branch_proj[branch_name](torch.cat([flat, hint], dim=1))

    def forward(self, x_whole, x_root, x_center, x_side, x_tip):
        features = [
            self._add_hint(self._encode(x_whole),  "whole",  x_whole.device),
            self._add_hint(self._encode(x_root),   "root",   x_root.device),
            self._add_hint(self._encode(x_center), "center", x_center.device),
            self._add_hint(self._encode(x_side),   "side",   x_side.device),
            self._add_hint(self._encode(x_tip),    "tip",    x_tip.device)
        ]
        fused = torch.cat(features, dim=1)
        return self.classifier(fused)

# -----------------------------------------------------------------------------
# æ¨¡åž‹äºŒï¼šç°¡æ½”çš„å–®ä¸€è¼¸å…¥æ¨¡åž‹ (SimpleTimmModel)
# -----------------------------------------------------------------------------
class SimpleTimmModel(nn.Module):
    def __init__(self, num_classes, backbone='convnext_base', feature_dim=512,img_size=224):
        super().__init__()
        print(f"Initializing SimpleTimmModel with backbone: {backbone}")
        # 1. å»ºç«‹ä¸€å€‹ kwargs å­—å…¸
        model_kwargs = {
            'pretrained': True,
            'num_classes': num_classes
        }

        # 2. æ™ºæ…§åˆ¤æ–·ï¼šåªæœ‰ ViT/Swin/DINO é¡žåž‹çš„æ¨¡åž‹æ‰éœ€è¦ img_size
        if 'vit' in backbone or 'swin' in backbone or 'dinov2' in backbone:
            print(f"  -> (ViT/Swin/DINO) å‚³éž img_size={img_size}")
            model_kwargs['img_size'] = img_size
        else:
            print(f"  -> (CNN) ä¸å‚³éž img_size")

        # 3. ä½¿ç”¨ **kwargs èªžæ³•ä¾†å»ºç«‹æ¨¡åž‹
        self.model = create_model(backbone, **model_kwargs)

    def forward(self, x_whole, x_root, x_center, x_side, x_tip):
        return self.model(x_whole)

# -----------------------------------------------------------------------------
# æ¨¡åž‹ä¸‰ï¼šå„ªåŒ–ç‰ˆï¼ä½¿ç”¨ Attention èžåˆçš„è¤‡é›œç¶²è·¯ (SignOrientedAttentionNetwork)
# -----------------------------------------------------------------------------
class SignOrientedAttentionNetwork(nn.Module):
    def __init__(self, num_classes=8, backbone='swin_base_patch4_window7_224', feature_dim=512):
        super().__init__()
        print(f"Initializing SignOrientedAttentionNetwork with backbone: {backbone}")

        self.encoder = create_model(backbone, pretrained=True, features_only=True)
        self.enc_dim = self.encoder.feature_info.channels()[-1]
        self.branch_hints = {
            "side":   [1,1,1,1,0,1,0,0], "tip":    [1,1,0,1,0,0,0,0],
            "center": [0,0,0,0,1,0,1,1], "root":   [0,1,0,0,1,0,0,0],
            "whole":  [1,1,1,1,1,1,1,1],
        }
        self.branch_proj = nn.ModuleDict({
            name: nn.Sequential(
                nn.Linear(self.enc_dim + num_classes, feature_dim),
                nn.ReLU(inplace=True)
            ) for name in self.branch_hints.keys()
        })
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.flatten = nn.Flatten()
        
        self.fusion_layer = nn.TransformerEncoderLayer(
            d_model=feature_dim,
            nhead=8,
            dim_feedforward=feature_dim * 2,
            dropout=0.2,
            activation='gelu',
            batch_first=True
        )

        self.classifier = nn.Sequential(
            nn.LayerNorm(feature_dim),
            nn.Linear(feature_dim, num_classes)
        )

    def _encode(self, x: torch.Tensor) -> torch.Tensor:
        feat = self.encoder(x)[-1]
        if feat.dim() == 4 and feat.shape[-1] == self.enc_dim:
            feat = feat.permute(0, 3, 1, 2).contiguous()
        return self.flatten(self.pool(feat)) if feat.dim() == 4 else feat

    def _add_hint(self, flat: torch.Tensor, branch_name: str, device) -> torch.Tensor:
        hint = torch.tensor(self.branch_hints[branch_name], device=device, dtype=torch.float32)
        hint = hint.unsqueeze(0).expand(flat.size(0), -1)
        return self.branch_proj[branch_name](torch.cat([flat, hint], dim=1))

    def forward(self, x_whole, x_root, x_center, x_side, x_tip):
        features = [
            self._add_hint(self._encode(x_whole),  "whole",  x_whole.device),
            self._add_hint(self._encode(x_root),   "root",   x_root.device),
            self._add_hint(self._encode(x_center), "center", x_center.device),
            self._add_hint(self._encode(x_side),   "side",   x_side.device),
            self._add_hint(self._encode(x_tip),    "tip",    x_tip.device)
        ]
        
        feature_sequence = torch.stack(features, dim=1)
        fused_sequence = self.fusion_layer(feature_sequence)
        fused_representation = fused_sequence[:, 0, :]
        
        return self.classifier(fused_representation)

# ============================================================================
# Vision Mamba Backbone: (æ‰‹å‹•æ­å»ºï¼Œå¾žé›¶è¨“ç·´)
# ============================================================================

class PatchEmbedding(nn.Module):
    """å°‡åœ–ç‰‡åˆ‡æˆ patches ä¸¦åµŒå…¥"""
    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=512):
        super().__init__()
        self.img_size = img_size
        self.patch_size = patch_size
        self.n_patches = (img_size // patch_size) ** 2
        
        self.proj = nn.Conv2d(in_chans, embed_dim, 
                              kernel_size=patch_size, stride=patch_size)
        
    def forward(self, x):
        x = self.proj(x)
        x = x.flatten(2)
        x = x.transpose(1, 2)
        return x



# -----------------------------------------------------------------------------
# è¼‰å…¥ MambaVision é è¨“ç·´æ¨¡åž‹
# -----------------------------------------------------------------------------
try:
    # 
    #  å”¯ä¸€çš„ä¿®æ”¹ï¼š ç§»é™¤ mamba_vision çš„åº•ç·š
    # 
    from mambavision import create_model as create_mamba_vision_model
    MAMBA_VISION_AVAILABLE = True
except ImportError:
    print("="*50)
    # 
    #  (å¯é¸) ä¹Ÿå¯ä»¥é †ä¾¿ä¿®æ”¹é€™è£¡çš„è­¦å‘Šè¨Šæ¯ï¼Œä¿æŒä¸€è‡´
    # 
    print("è­¦å‘Šï¼šæ‰¾ä¸åˆ° 'mambavision'ã€‚") 
    print("è«‹ç¢ºèªå·²åœ¨ MambaVision repo ç›®éŒ„åŸ·è¡Œ: pip install . --no-deps")
    print("'MambaVision' ç³»åˆ—æ¨¡åž‹å°‡ç„¡æ³•ä½¿ç”¨ã€‚")
    print("="*50)
    MAMBA_VISION_AVAILABLE = False

# ============================================================================
# (æ¨¡åž‹å) ðŸ†• ä½¿ç”¨ MambaVision é è¨“ç·´æ¨¡åž‹ä½œç‚º Backboneï¼ˆäº”åˆ†æ”¯ï¼‰
# ============================================================================
class SignOrientedMambaVisionNetwork(nn.Module):
    """
    äº”åˆ†æ”¯æ¨¡åž‹ï¼Œä½¿ç”¨ MambaVision é è¨“ç·´æ¨¡åž‹ä½œç‚º Backbone
    """
    def __init__(self, num_classes=8, mamba_vision_model='mamba_vision_T', 
                 feature_dim=512, pretrained=True, freeze_backbone=False):
        super().__init__()
        
        if not MAMBA_VISION_AVAILABLE:
            raise ImportError("è«‹å…ˆå®‰è£ mamba-vision: pip install mamba-vision")
        
        print(f"Initializing SignOrientedMambaVisionNetwork")
        print(f"  -> MambaVision æ¨¡åž‹: {mamba_vision_model}")
        print(f"  -> ä½¿ç”¨é è¨“ç·´: {pretrained}")
        print(f"  -> å‡çµ Backbone: {freeze_backbone}")
        
        # è¼‰å…¥ MambaVision é è¨“ç·´æ¨¡åž‹ï¼ˆè¨­å®š num_classes=0 ä¾†ç§»é™¤åˆ†é¡žé ­ï¼‰
        self.encoder = create_mamba_vision_model(
            mamba_vision_model,
            pretrained=pretrained,
            num_classes=0  # ç§»é™¤åŽŸå§‹åˆ†é¡žé ­ï¼Œåªä¿ç•™ç‰¹å¾µæå–éƒ¨åˆ†
        )
        
        # å¦‚æžœéœ€è¦å‡çµ backbone
        if freeze_backbone:
            print("  -> å‡çµ MambaVision Backbone åƒæ•¸")
            for param in self.encoder.parameters():
                param.requires_grad = False
        
        # ç²å– MambaVision çš„è¼¸å‡ºç‰¹å¾µç¶­åº¦
        # ä¸åŒçš„ MambaVision æ¨¡åž‹æœ‰ä¸åŒçš„è¼¸å‡ºç¶­åº¦
        model_dims = {
            'mamba_vision_T': 640,   # Tiny
            'mamba_vision_T2': 640,  # Tiny2
            'mamba_vision_S': 768,   # Small
            'mamba_vision_B': 1024,  # Base
            'mamba_vision_L': 1024,  # Large
        }
        self.enc_dim = model_dims.get(mamba_vision_model, 640)
        
        self.branch_hints = {
            "side":   [1,1,1,1,0,1,0,0], 
            "tip":    [1,1,0,1,0,0,0,0],
            "center": [0,0,0,0,1,0,1,1], 
            "root":   [0,1,0,0,1,0,0,0],
            "whole":  [1,1,1,1,1,1,1,1],
        }
        
        # åˆ†æ”¯æŠ•å½±å±¤ï¼šå°‡ MambaVision ç‰¹å¾µ + hint æ˜ å°„åˆ°çµ±ä¸€ç¶­åº¦
        self.branch_proj = nn.ModuleDict({
            name: nn.Sequential(
                nn.Linear(self.enc_dim + num_classes, feature_dim),
                nn.ReLU(inplace=True),
                nn.LayerNorm(feature_dim),
                nn.Dropout(0.1)
            ) for name in self.branch_hints.keys()
        })
        
        # æœ€çµ‚åˆ†é¡žå™¨
        fused_dim = feature_dim * 5
        self.classifier = nn.Sequential(
            nn.Linear(fused_dim, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )
    
    def _add_hint(self, flat: torch.Tensor, branch_name: str, device) -> torch.Tensor:
        hint = torch.tensor(self.branch_hints[branch_name], device=device, dtype=torch.float32)
        hint = hint.unsqueeze(0).expand(flat.size(0), -1)
        return self.branch_proj[branch_name](torch.cat([flat, hint], dim=1))
    
    def forward(self, x_whole, x_root, x_center, x_side, x_tip):
        # ä½¿ç”¨ MambaVision encoder æå–ç‰¹å¾µ
        features = [
            self._add_hint(self.encoder(x_whole),  "whole",  x_whole.device),
            self._add_hint(self.encoder(x_root),   "root",   x_root.device),
            self._add_hint(self.encoder(x_center), "center", x_center.device),
            self._add_hint(self.encoder(x_side),   "side",   x_side.device),
            self._add_hint(self.encoder(x_tip),    "tip",    x_tip.device)
        ]
        
        fused = torch.cat(features, dim=1)
        return self.classifier(fused)


# ============================================================================
# (æ¨¡åž‹åä¸€) ðŸ†• ç°¡åŒ–ç‰ˆï¼šå–®åˆ†æ”¯ MambaVisionï¼ˆå¿«é€Ÿæ¸¬è©¦ç”¨ï¼‰
# ============================================================================
class SimpleMambaVision(nn.Module):
    """
    æœ€ç°¡å–®çš„ MambaVision æ¨¡åž‹ (åªç”¨ whole åˆ†æ”¯)
    é©åˆå¿«é€Ÿæ¸¬è©¦å’Œå°æ¯”å¯¦é©—
    """
    def __init__(self, num_classes=8, mamba_vision_model='mamba_vision_T', 
                 pretrained=True, freeze_backbone=False):
        super().__init__()
        
        if not MAMBA_VISION_AVAILABLE:
            raise ImportError("è«‹å…ˆå®‰è£ mamba-vision: pip install mamba-vision")
        
        print(f"Initializing SimpleMambaVision")
        print(f"  -> MambaVision æ¨¡åž‹: {mamba_vision_model}")
        print(f"  -> ä½¿ç”¨é è¨“ç·´: {pretrained}")
        print(f"  -> å‡çµ Backbone: {freeze_backbone}")
        
        # ç›´æŽ¥ä½¿ç”¨ MambaVision çš„å®Œæ•´æ¨¡åž‹ï¼ˆåŒ…å«åˆ†é¡žé ­ï¼‰
        self.model = create_mamba_vision_model(
            mamba_vision_model,
            pretrained=pretrained,
            num_classes=num_classes
        )
        
        # å¦‚æžœéœ€è¦å‡çµ backboneï¼ˆä¿ç•™åˆ†é¡žé ­å¯è¨“ç·´ï¼‰
        if freeze_backbone:
            print("  -> å‡çµ MambaVision Backboneï¼Œåªè¨“ç·´åˆ†é¡žé ­")
            for name, param in self.model.named_parameters():
                if 'head' not in name.lower():  # åªå‡çµéž head çš„åƒæ•¸
                    param.requires_grad = False
    
    def forward(self, x_whole, x_root, x_center, x_side, x_tip):
        # åªä½¿ç”¨ whole åˆ†æ”¯
        return self.model(x_whole)


# ============================================================================
# (æ¨¡åž‹åäºŒ) ðŸ†• MambaVision + Mamba Fusionï¼ˆæ··åˆæž¶æ§‹ï¼‰
# ============================================================================
class MambaVisionWithMambaFusion(nn.Module):
    """
    ä½¿ç”¨ MambaVision ä½œç‚ºç‰¹å¾µæå–å™¨ + Mamba æ¨¡çµ„é€²è¡Œç‰¹å¾µèžåˆ
    çµåˆäº†å…©ç¨® Mamba çš„å„ªå‹¢
    """
    def __init__(self, num_classes=8, mamba_vision_model='mamba_vision_T', 
                 feature_dim=512, d_state=16, pretrained=True, freeze_backbone=False):
        super().__init__()
        
        if not MAMBA_VISION_AVAILABLE:
            raise ImportError("è«‹å…ˆå®‰è£ mamba-vision: pip install mamba-vision")
        
        print(f"Initializing MambaVisionWithMambaFusion")
        print(f"  -> MambaVision æ¨¡åž‹: {mamba_vision_model}")
        print(f"  -> Mamba èžåˆå±¤ d_state: {d_state}")
        
        # MambaVision ç‰¹å¾µæå–å™¨
        self.encoder = create_mamba_vision_model(
            mamba_vision_model,
            pretrained=pretrained,
            num_classes=0
        )
        
        if freeze_backbone:
            for param in self.encoder.parameters():
                param.requires_grad = False
        
        model_dims = {
            'mamba_vision_T': 640, 'mamba_vision_T2': 640,
            'mamba_vision_S': 768, 'mamba_vision_B': 1024,
            'mamba_vision_L': 1024,
        }
        self.enc_dim = model_dims.get(mamba_vision_model, 640)
        
        self.branch_hints = {
            "side":   [1,1,1,1,0,1,0,0], "tip":    [1,1,0,1,0,0,0,0],
            "center": [0,0,0,0,1,0,1,1], "root":   [0,1,0,0,1,0,0,0],
            "whole":  [1,1,1,1,1,1,1,1],
        }
        
        self.branch_proj = nn.ModuleDict({
            name: nn.Sequential(
                nn.Linear(self.enc_dim + num_classes, feature_dim),
                nn.ReLU(inplace=True),
                nn.LayerNorm(feature_dim)
            ) for name in self.branch_hints.keys()
        })
        
        # ä½¿ç”¨ Mamba é€²è¡Œç‰¹å¾µèžåˆ
        self.mamba_fusion = Mamba(
            d_model=feature_dim,
            d_state=d_state,
            d_conv=4,
            expand=2
        )
        
        self.classifier = nn.Sequential(
            nn.LayerNorm(feature_dim),
            nn.Dropout(0.2),
            nn.Linear(feature_dim, num_classes)
        )
    
    def _add_hint(self, flat: torch.Tensor, branch_name: str, device) -> torch.Tensor:
        hint = torch.tensor(self.branch_hints[branch_name], device=device, dtype=torch.float32)
        hint = hint.unsqueeze(0).expand(flat.size(0), -1)
        return self.branch_proj[branch_name](torch.cat([flat, hint], dim=1))
    
    def forward(self, x_whole, x_root, x_center, x_side, x_tip):
        features = [
            self._add_hint(self.encoder(x_whole),  "whole",  x_whole.device),
            self._add_hint(self.encoder(x_root),   "root",   x_root.device),
            self._add_hint(self.encoder(x_center), "center", x_center.device),
            self._add_hint(self.encoder(x_side),   "side",   x_side.device),
            self._add_hint(self.encoder(x_tip),    "tip",    x_tip.device)
        ]
        
        feature_sequence = torch.stack(features, dim=1)
        mamba_output = self.mamba_fusion(feature_sequence)
        fused_representation = mamba_output[:, -1, :]
        
        return self.classifier(fused_representation)
