# evaluate_folds.py (v7 - ä¿®æ­£ SyntaxError)

import torch
import torch.nn as nn
import argparse
import json
import os
from PIL import Image
import numpy as np
import pandas as pd
import warnings
from tqdm import tqdm

# --- é—œéµï¼šå¾ä½ çš„å°ˆæ¡ˆåŒ¯å…¥ ---
from model import (
    SignOrientedNetwork, 
    SimpleTimmModel, 
    SignOrientedAttentionNetwork,
    SignOrientedMambaVisionNetwork,
    SimpleMambaVision,
    MambaVisionWithMambaFusion
)
from dataset import TongueDataset # å‡è¨­ä½ çš„ TongueDataset åœ¨ dataset.py
from torch.utils.data import DataLoader

# --- åŒ¯å…¥è©•ä¼°æŒ‡æ¨™ ---
from sklearn.metrics import f1_score, jaccard_score, accuracy_score

warnings.filterwarnings('ignore')

# --- é—œéµï¼šå¾ train.py å®Œæ•´è¤‡è£½ get_model å‡½å¼ ---
def get_model(args):
    """æ ¹æ“š args å»ºç«‹å°æ‡‰çš„æ¨¡å‹"""
    
    # SimpleTimmModel - å–®åˆ†æ”¯ CNN
    if args.model == 'Simple':
        return SimpleTimmModel(
            num_classes=len(args.label_cols),
            backbone=args.backbone,
            img_size=args.img_size
        )
    
    # SignOriented - åŸå§‹äº”åˆ†æ”¯æ¨¡å‹
    elif args.model == 'SignOriented':
        return SignOrientedNetwork(
            num_classes=len(args.label_cols),
            backbone=args.backbone,
            feature_dim=args.feature_dim
        )
    
    # SignOrientedAttention - Transformer Attention èåˆ
    elif args.model == 'SignOrientedAttention':
        return SignOrientedAttentionNetwork(
            num_classes=len(args.label_cols),
            backbone=args.backbone,
            feature_dim=args.feature_dim
        )
    elif args.model == 'MambaVision':
        return SignOrientedMambaVisionNetwork(
            num_classes=len(args.label_cols),
            mamba_vision_model=args.mamba_vision_model,
            feature_dim=args.feature_dim,
            pretrained=args.pretrained,
            freeze_backbone=args.freeze_backbone
        )
    
    elif args.model == 'SimpleMambaVision':
        return SimpleMambaVision(
            num_classes=len(args.label_cols),
            mamba_vision_model=args.mamba_vision_model,
            pretrained=args.pretrained,
            freeze_backbone=args.freeze_backbone
        )
    
    elif args.model == 'MambaVisionFusion':
        return MambaVisionWithMambaFusion(
            num_classes=len(args.label_cols),
            mamba_vision_model=args.mamba_vision_model,
            feature_dim=args.feature_dim,
            d_state=args.d_state,
            pretrained=args.pretrained,
            freeze_backbone=args.freeze_backbone
        )
    
    else:
        raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹æ¶æ§‹: {args.model}")

@torch.no_grad()
def evaluate_fold(model, val_loader, device, thresholds):
    """åœ¨å–®ä¸€ fold ä¸Šé€²è¡Œè©•ä¼°"""
    model.eval()
    all_probs, all_labels = [], []
    
    for (x_whole, x_root, x_center, x_side, x_tip), labels in tqdm(val_loader, desc="Evaluating", leave=False):
        logits = model(
            x_whole.to(device), 
            x_root.to(device), 
            x_center.to(device), 
            x_side.to(device), 
            x_tip.to(device)
        )
        probs = torch.sigmoid(logits)
        all_probs.append(probs.cpu().numpy())
        all_labels.append(labels.cpu().numpy())
        
    P = np.vstack(all_probs) # é æ¸¬æ©Ÿç‡
    Y = np.vstack(all_labels) # çœŸå¯¦æ¨™ç±¤
    
    # ä½¿ç”¨å‚³å…¥çš„ thresholds é€²è¡ŒäºŒå€¼åŒ–
    T = np.array(thresholds)
    Preds = (P > T).astype(int)
    
    # è¨ˆç®—æŒ‡æ¨™
    per_class_f1 = f1_score(Y, Preds, average=None, zero_division=0)
    avg_f1_macro = np.mean(per_class_f1)
    jaccard = jaccard_score(Y, Preds, average='samples', zero_division=0)
    subset_acc = accuracy_score(Y, Preds)
    per_class_acc = (Y == Preds).astype(float).mean(axis=0) # (8,) 
    avg_acc_label_based = np.mean(per_class_acc)
    
    return per_class_f1, avg_f1_macro, jaccard, subset_acc, avg_acc_label_based, per_class_acc


# --- ä¸»ç¨‹å¼ ---
def main():
    parser = argparse.ArgumentParser(description='K-Fold äº¤å‰é©—è­‰è©•ä¼° (K-Fold Evaluation)')
    
    parser.add_argument('--experiment_name', type=str, required=True,
                        help='å¯¦é©—åç¨± (ä¾‹å¦‚: Simple_mobilenetv3_large_100_KD)')
    parser.add_argument('--model_dir', type=str, default=".",
                        help='å­˜æ”¾ .pth æ¬Šé‡æª”å’Œ .json æª”æ¡ˆçš„ç›®éŒ„')
    parser.add_argument('--image_root', type=str, default='images', 
                        help='åœ–ç‰‡æ ¹ç›®éŒ„ (dataset.py éœ€è¦)')
    parser.add_argument('--num_folds', type=int, default=5,
                        help='K-Fold çš„ K å€¼ (ç­‰æ–¼æ¨¡å‹æ•¸é‡)')
    parser.add_argument('--img_size', type=int, default=224, help='è¼¸å…¥åœ–ç‰‡å¤§å°')
    parser.add_argument('--feature_dim', type=int, default=512, help='ç‰¹å¾µç¶­åº¦')
    parser.add_argument('--d_state', type=int, default=16, help='Mamba ç‹€æ…‹ç©ºé–“ç¶­åº¦')
    parser.add_argument('--mamba_vision_model', type=str, default='mamba_vision_T', help='MambaVision æ¨¡å‹å¤§å°')
    parser.add_argument('--pretrained', action='store_true', default=True)
    parser.add_argument('--freeze_backbone', action='store_true', default=False)
    parser.add_argument('--num_workers', type=int, default=4) 
    parser.add_argument('--batch_size', type=int, default=32) 
    
    args = parser.parse_args()
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # 1. "HACK": è§£æ get_model æ‰€éœ€çš„åƒæ•¸
    thresh_path = os.path.join(args.model_dir, f"{args.experiment_name}_final_best_thresholds.json")
    if not os.path.exists(thresh_path):
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° {thresh_path}ã€‚ç„¡æ³•ç²å–æ¨™ç±¤é †åºã€‚")
        return
    with open(thresh_path, 'r', encoding='utf-8') as f:
        thresholds_data = json.load(f)
    
    labels = list(thresholds_data.keys())
    args.label_cols = labels
    
    try:
        parse_name = args.experiment_name
        if parse_name.endswith('_KD'):
            parse_name = parse_name[:-3] 

        parts = parse_name.split('_', 1) 
        args.model = parts[0]
        model_specific_name = parts[1]
        
        if 'mamba' in args.model.lower():
            args.mamba_vision_model = model_specific_name
            print(f"  -> è‡ªå‹•è§£æ: Model = {args.model}, Mamba = {args.mamba_vision_model}")
        else:
            args.backbone = model_specific_name 
            print(f"  -> è‡ªå‹•è§£æ: Model = {args.model}, Backbone = {args.backbone}")
            
    except Exception as e:
        print(f"âŒ éŒ¯èª¤ï¼šç„¡æ³•å¾ '{args.experiment_name}' è§£ææ¨¡å‹åç¨±ã€‚éŒ¯èª¤: {e}")
        return

    # 2. ğŸ”¥ è¨ˆç®—æ¨¡å‹åƒæ•¸èˆ‡å¤§å°
    print("  -> è¨ˆç®—æ¨¡å‹åƒæ•¸èˆ‡å¤§å°...")
    total_params = 0
    try:
        rep_model = get_model(args) 
        total_params = sum(p.numel() for p in rep_model.parameters())
        print(f"  -> æ¨¡å‹åƒæ•¸ (Params): {total_params:,}")
        del rep_model 
    except Exception as e:
        print(f"  -> è­¦å‘Šï¼šè¨ˆç®—æ¨¡å‹åƒæ•¸å¤±æ•—: {e}")

    model_path_1 = os.path.join(args.model_dir, f"{args.experiment_name}_fold1.pth")
    model_size_mb = 0.0
    if os.path.exists(model_path_1):
        model_size_mb = os.path.getsize(model_path_1) / (1024 * 1024)
        print(f"  -> æ¨¡å‹å¤§å° (Size): {model_size_mb:.2f} MB")
    else:
        print(f"  -> è­¦å‘Š: æ‰¾ä¸åˆ° {model_path_1}ï¼Œç„¡æ³•è¨ˆç®—æ¨¡å‹å¤§å°ã€‚")

    # 3. å„²å­˜ 5 å€‹ Fold çš„æ‰€æœ‰æŒ‡æ¨™
    all_fold_metrics = [] 
    for i in range(1, args.num_folds + 1):
        print("\n" + "="*50)
        print(f"  Processing Fold {i}/{args.num_folds}")
        print("="*50)
        
        # A. è¼‰å…¥è©² Fold çš„é©—è­‰é›† CSV
        val_csv_path = f'val_fold{i}.csv'
        if not os.path.exists(val_csv_path):
            print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° {val_csv_path}")
            continue
        
        val_set = TongueDataset(val_csv_path, args.image_root, args.label_cols, is_train=False)
        val_loader = DataLoader(val_set, batch_size=args.batch_size, shuffle=False, 
                              num_workers=args.num_workers, pin_memory=True)
        print(f"  âœ“ è¼‰å…¥ {len(val_set)} ç­†é©—è­‰è³‡æ–™ from {val_csv_path}")

        # B. è¼‰å…¥è©² Fold çš„æ¨¡å‹
        model_path = os.path.join(args.model_dir, f"{args.experiment_name}_fold{i}.pth")
        if not os.path.exists(model_path):
            print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° {model_path}")
            continue
            
        model = get_model(args) 
        model.load_state_dict(torch.load(model_path, map_location=device)['model_state_dict'])
        model.to(device)
        print(f"  âœ“ è¼‰å…¥æ¨¡å‹ from {model_path}")
        
        # C. è¼‰å…¥è©² Fold çš„ *å°ˆå±¬* Thresholds
        fold_thresh_path = os.path.join(args.model_dir, f"{args.experiment_name}_fold{i}_best_thresholds.json")
        if not os.path.exists(fold_thresh_path):
            print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° {fold_thresh_path}")
            continue
            
        with open(fold_thresh_path, 'r', encoding='utf-8') as f:
            fold_thresh_data = json.load(f)
        
        fold_thresholds = [fold_thresh_data[label] for label in labels]
        print(f"  âœ“ è¼‰å…¥ Fold {i} å°ˆå±¬ thresholds")

        # D. åŸ·è¡Œè©•ä¼°
        per_class_f1, avg_f1_macro, jaccard, subset_acc, avg_acc_label_based, per_class_acc = evaluate_fold(
            model, val_loader, device, fold_thresholds
        )
        
        # å„²å­˜çµæœ
        fold_results = {
            'per_class_f1': per_class_f1,
            'Average': avg_f1_macro,
            'Jaccard': jaccard,
            'SubsetAcc': subset_acc,
            'AvgAccLabel': avg_acc_label_based, 
            'per_class_acc': per_class_acc 
        }
        all_fold_metrics.append(fold_results)

    # 4. è¿´åœˆçµæŸï¼Œè¨ˆç®— mean Â± std ä¸¦å°å‡ºå®Œæ•´è¡¨æ ¼
    print("\n" + "="*120) 
    print(f"  {args.experiment_name} çš„ 5-Fold äº¤å‰é©—è­‰çµæœ (mean% Â± std%)")
    print("="*120)
    
    header = f"{'Model':<25} | {'Avg F1 (Macro)':<15} | {'Avg Acc (Label)':<15} | {'Subset Acc':<15} | {'Jaccard':<15} | {'Params (M)':<10} | {'Size (MB)':<10}"
    print(header)
    print("-" * len(header))
    
    # æå–æ‰€æœ‰æŒ‡æ¨™
    avg_f1s = [m['Average'] for m in all_fold_metrics]
    jaccards = [m['Jaccard'] for m in all_fold_metrics]
    subset_accs = [m['SubsetAcc'] for m in all_fold_metrics]
    avg_acc_labels = [m['AvgAccLabel'] for m in all_fold_metrics] 
    
    # --- è¨ˆç®— Mean Â± Std (ä¸¦è½‰ç‚ºç™¾åˆ†æ¯”) ---
    def format_metric(values):
        mean = np.mean(values) * 100
        std = np.std(values) * 100
        return f"{mean:.2f} Â± {std:.2f}"
    
    avg_f1_str = format_metric(avg_f1s)
    avg_acc_label_str = format_metric(avg_acc_labels) 
    subset_acc_str = format_metric(subset_accs)
    jaccard_str = format_metric(jaccards)

    # --- æ ¼å¼åŒ– Params å’Œ Size ---
    params_m_str = f"{total_params / 1_000_000:.2f} M"
    size_mb_str = f"{model_size_mb:.2f} MB"
    
    model_name_short = args.experiment_name[:25] 
    data_row = f"{model_name_short:<25} | {avg_f1_str:<15} | {avg_acc_label_str:<15} | {subset_acc_str:<15} | {jaccard_str:<15} | {params_m_str:<10} | {size_mb_str:<10}"
    print(data_row)

    # 5. å°å‡º F1-Score ç´°é …è¡¨æ ¼
    print("\n" + "-"*120)
    print("  F1-Score (mean% Â± std%) ç´°ç¯€")
    
    col_width = max(max(len(label) for label in labels), 10) 
    header_parts = [f"{label:<{col_width}}" for label in labels]
    table_width = len("  " + " | ".join(header_parts))
    print("  " + "-"*(table_width-2))
    print("  " + " | ".join(header_parts))
    
    all_per_class_f1s = np.array([m['per_class_f1'] for m in all_fold_metrics])
    f1_means = np.mean(all_per_class_f1s, axis=0) * 100
    f1_stds = np.std(all_per_class_f1s, axis=0) * 100
    
    mean_parts = [f"{m:>{col_width}.2f}" for m in f1_means]
    std_parts  = [f"{s:>{col_width-1}.2f}" for s in f1_stds] 
    
    print("  " + " | ".join(mean_parts))
    print("  " + " | ".join([f"Â±{s}" for s in std_parts]))
    
    # 6. å°å‡º Accuracy ç´°é …è¡¨æ ¼
    print("\n" + "-"*120)
    print("  Accuracy (mean% Â± std%) ç´°ç¯€")
    print("  " + "-"*(table_width-2))
    
    # ğŸ”¥ --- é—œéµä¿®æ”¹ (v7) ---
    print("  " + " | ".join(header_parts)) # ç§»é™¤äº†å¤šé¤˜çš„ 'S'
    # --- ä¿®æ”¹çµæŸ ---
    
    all_per_class_accs = np.array([m['per_class_acc'] for m in all_fold_metrics])
    acc_means = np.mean(all_per_class_accs, axis=0) * 100
    acc_stds = np.std(all_per_class_accs, axis=0) * 100
    
    mean_parts_acc = [f"{m:>{col_width}.2f}" for m in acc_means]
    std_parts_acc  = [f"{s:>{col_width-1}.2f}" for s in acc_stds]
    
    print("  " + " | ".join(mean_parts_acc))
    print("  " + " | ".join([f"Â±{s}" for s in std_parts_acc]))
    print("="*120)

if __name__ == '__main__':
    main()
